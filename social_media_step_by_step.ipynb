{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49de6337",
   "metadata": {},
   "source": [
    "\n",
    "# Social Media Trends — Step-by-Step Notebook\n",
    "\n",
    "This notebook walks through:\n",
    "1. Loading & cleaning your dataset  \n",
    "2. Feature engineering (time features, engagement rate)  \n",
    "3. Hashtag **time-series** analysis  \n",
    "4. Hashtag **co-occurrence** **graph**  \n",
    "5. **Region × Platform** heatmap (by engagement)  \n",
    "6. Baseline **ML** model to predict `Engagement_Level`  \n",
    "\n",
    "> **Assumed columns:**  \n",
    "`['Post_ID','Post_Date','Platform','Hashtag','Content_Type','Region','Views','Likes','Shares','Comments','Engagement_Level']`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bf233a",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acb22e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If you don't have networkx installed, uncomment:\n",
    "# !pip install networkx scikit-learn\n",
    "\n",
    "import os, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import networkx as nx\n",
    "except Exception as e:\n",
    "    nx = None\n",
    "    print(\"[Warning] networkx not available; co-occurrence graph will be skipped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109df6bd",
   "metadata": {},
   "source": [
    "## 1. Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ⬇️ Edit this path to your CSV\n",
    "CSV_PATH = \"path/to/your.csv\"  # e.g., \"data/social_trends.csv\"\n",
    "DATE_COL = \"Post_Date\"\n",
    "\n",
    "# --- Load ---\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Parse datetime\n",
    "if DATE_COL in df.columns:\n",
    "    df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"coerce\", utc=True).dt.tz_localize(None)\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6153b63",
   "metadata": {},
   "source": [
    "## 2. Basic cleaning & preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae2fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop rows with missing dates (if needed)\n",
    "if DATE_COL in df.columns:\n",
    "    df = df.dropna(subset=[DATE_COL])\n",
    "\n",
    "# Ensure numeric types for metrics\n",
    "for c in [\"Views\",\"Likes\",\"Shares\",\"Comments\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "print(df.dtypes)\n",
    "df.sample(min(5, len(df)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6793afb2",
   "metadata": {},
   "source": [
    "## 3. Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35ae30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Time features\n",
    "if DATE_COL in df.columns:\n",
    "    dt = df[DATE_COL]\n",
    "    df[\"Year\"] = dt.dt.year\n",
    "    df[\"Month\"] = dt.dt.month\n",
    "    df[\"Week\"] = dt.dt.isocalendar().week.astype(int)\n",
    "    df[\"Weekday\"] = dt.dt.dayofweek\n",
    "    df[\"Hour\"] = dt.dt.hour\n",
    "\n",
    "# Engagement rate\n",
    "for c in [\"Views\",\"Likes\",\"Shares\",\"Comments\"]:\n",
    "    if c not in df.columns:\n",
    "        df[c] = 0\n",
    "\n",
    "df[\"Engagement_Rate\"] = (df[\"Likes\"].fillna(0) + df[\"Shares\"].fillna(0) + df[\"Comments\"].fillna(0)) / (\n",
    "    df[\"Views\"].replace(0, np.nan)\n",
    ")\n",
    "df[\"Engagement_Rate\"] = df[\"Engagement_Rate\"].fillna(0.0)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6559283a",
   "metadata": {},
   "source": [
    "## 4. Hashtag time-series (top-N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480ae0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "RESAMPLE = \"W\"     # 'D','W','M'\n",
    "TOP_HASHTAGS = 6   # change as needed\n",
    "METRIC = \"Engagement_Rate\" if \"Engagement_Rate\" in df.columns else \"Likes\"\n",
    "\n",
    "if \"Hashtag\" in df.columns and DATE_COL in df.columns:\n",
    "    dft = df.dropna(subset=[\"Hashtag\"]).copy()\n",
    "    dft[\"Hashtag\"] = dft[\"Hashtag\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "    top_tags = dft[\"Hashtag\"].value_counts().head(TOP_HASHTAGS).index.tolist()\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for tag in top_tags:\n",
    "        temp = dft[dft[\"Hashtag\"] == tag].set_index(DATE_COL).sort_index()\n",
    "        ts = temp[METRIC].resample(RESAMPLE).mean()\n",
    "        plt.plot(ts.index, ts.values, label=tag)\n",
    "\n",
    "    plt.title(f\"{METRIC} over time — Top {len(top_tags)} hashtags (resample={RESAMPLE})\")\n",
    "    plt.xlabel(\"Date\"); plt.ylabel(METRIC); plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Hashtag or Post_Date column missing — skipping time-series.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7407a587",
   "metadata": {},
   "source": [
    "## 5. Hashtag co-occurrence graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9efbe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if \"Hashtag\" not in df.columns:\n",
    "    print(\"No 'Hashtag' column — skipping co-occurrence graph.\")\n",
    "elif nx is None:\n",
    "    print(\"networkx not installed — skipping co-occurrence graph.\")\n",
    "else:\n",
    "    # Assume comma-separated hashtags per post. Single hashtags are okay (edges require ≥2 per post).\n",
    "    tags_series = (\n",
    "        df[\"Hashtag\"].astype(str)\n",
    "        .str.lower()\n",
    "        .str.replace(\" \", \"\", regex=False)\n",
    "        .str.split(\",\")\n",
    "    )\n",
    "\n",
    "    from collections import Counter\n",
    "    edge_counter = Counter()\n",
    "\n",
    "    for tags in tags_series:\n",
    "        tags = [t for t in tags if t]\n",
    "        unique = sorted(set(tags))\n",
    "        for i in range(len(unique)):\n",
    "            for j in range(i+1, len(unique)):\n",
    "                a, b = unique[i], unique[j]\n",
    "                edge_counter[(a, b)] += 1\n",
    "\n",
    "    # Build graph with a simple threshold for readability\n",
    "    MIN_EDGE_WEIGHT = 2\n",
    "    G = nx.Graph()\n",
    "    for (a, b), w in edge_counter.items():\n",
    "        if w >= MIN_EDGE_WEIGHT:\n",
    "            G.add_edge(a, b, weight=w)\n",
    "\n",
    "    if len(G.nodes) == 0:\n",
    "        print(\"No co-occurring hashtag pairs ≥ threshold; adjust MIN_EDGE_WEIGHT.\")\n",
    "    else:\n",
    "        deg = dict(G.degree())\n",
    "        node_sizes = [50 + 20*deg[n] for n in G.nodes()]\n",
    "        pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "        plt.figure(figsize=(12,8))\n",
    "        nx.draw_networkx_nodes(G, pos, node_size=node_sizes)\n",
    "        nx.draw_networkx_edges(G, pos, width=[0.5 + 0.3*G[u][v]['weight'] for u, v in G.edges()])\n",
    "        labels = {n: n if deg[n] >= 2 else \"\" for n in G.nodes()}\n",
    "        nx.draw_networkx_labels(G, pos, labels=labels, font_size=8)\n",
    "        plt.title(\"Hashtag Co-occurrence Graph (labels shown for degree ≥ 2)\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed32eda",
   "metadata": {},
   "source": [
    "## 6. Region × Platform heatmap (mean engagement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472c1c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if (\"Region\" in df.columns) and (\"Platform\" in df.columns):\n",
    "    agg = \"Engagement_Rate\" if \"Engagement_Rate\" in df.columns else (\"Likes\" if \"Likes\" in df.columns else None)\n",
    "    if agg is None:\n",
    "        print(\"No numeric engagement column found; skipping heatmap.\")\n",
    "    else:\n",
    "        pivot = df.pivot_table(index=\"Region\", columns=\"Platform\", values=agg, aggfunc=\"mean\").fillna(0.0)\n",
    "        fig, ax = plt.subplots(figsize=(10,6))\n",
    "        im = ax.imshow(pivot.values, aspect=\"auto\")\n",
    "        ax.set_xticks(range(len(pivot.columns)))\n",
    "        ax.set_xticklabels(pivot.columns, rotation=45, ha=\"right\")\n",
    "        ax.set_yticks(range(len(pivot.index)))\n",
    "        ax.set_yticklabels(pivot.index)\n",
    "        ax.set_title(f\"{agg} — Region × Platform (mean)\")\n",
    "        cbar = fig.colorbar(im, ax=ax, shrink=0.8)\n",
    "        cbar.set_label(agg)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Region or Platform missing — skipping heatmap.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe88f76",
   "metadata": {},
   "source": [
    "## 7. ML: Predict `Engagement_Level` (baseline Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4457873",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "if \"Engagement_Level\" not in df.columns:\n",
    "    print(\"No 'Engagement_Level' column — skipping ML.\")\n",
    "else:\n",
    "    cat_cols = [c for c in [\"Platform\",\"Content_Type\",\"Region\",\"Hashtag\"] if c in df.columns]\n",
    "    num_cols = [c for c in [\"Views\",\"Likes\",\"Shares\",\"Comments\",\"Engagement_Rate\",\"Hour\",\"Weekday\",\"Month\"] if c in df.columns]\n",
    "\n",
    "    X = df[cat_cols + num_cols].copy()\n",
    "    y = df[\"Engagement_Level\"].astype(str)\n",
    "\n",
    "    # Reduce hashtag cardinality\n",
    "    if \"Hashtag\" in X.columns:\n",
    "        freq = X[\"Hashtag\"].astype(str).value_counts()\n",
    "        top = set(freq.head(50).index)\n",
    "        X[\"Hashtag\"] = X[\"Hashtag\"].where(X[\"Hashtag\"].isin(top), other=\"_other_\")\n",
    "\n",
    "    pre = ColumnTransformer([\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", StandardScaler(), num_cols)\n",
    "    ])\n",
    "\n",
    "    clf = Pipeline([\n",
    "        (\"pre\", pre),\n",
    "        (\"rf\", RandomForestClassifier(n_estimators=300, random_state=42, class_weight=\"balanced\"))\n",
    "    ])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(\"[Classification report]\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    labels = sorted(y.unique())\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    im = ax.imshow(cm, aspect=\"auto\")\n",
    "    ax.set_xticks(range(len(labels))); ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "    ax.set_yticks(range(len(labels))); ax.set_yticklabels(labels)\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
    "    ax.set_title(\"Confusion Matrix — Engagement_Level\")\n",
    "    fig.colorbar(im, ax=ax, shrink=0.8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
